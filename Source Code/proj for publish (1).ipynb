{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_HIwZR22sPB"
      },
      "outputs": [],
      "source": [
        "from SPARQLWrapper import SPARQLWrapper, JSON\n",
        "import rdflib\n",
        "from rdflib import Graph, URIRef, BNode, RDF\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig\n",
        "import openai\n",
        "import pandas as pd\n",
        "import google.generativeai as genai\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDtgnIqK2uho",
        "outputId": "1394d1a6-c149-4083-f1a5-52765912f96b"
      },
      "outputs": [],
      "source": [
        "# create empty RDF graph\n",
        "org_ontology = Graph()\n",
        "org_ontology.parse(\"F:/main_proj/era_ontology.ttl\")   # parse our complete ontology\n",
        "endpoint_url ='https://virtuoso.ecdp.tech.ec.europa.eu/sparql'\n",
        "\n",
        "#GOOGLE_API_KEY=userdata.get('gemini_key')\n",
        "genai.configure(api_key= \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZmizoyM55JZb"
      },
      "outputs": [],
      "source": [
        "# function that excute SPARQL query and return results\n",
        "def execute_sparql_query(endpoint_url, query):\n",
        "    sparql = SPARQLWrapper(endpoint_url)\n",
        "    sparql.setQuery(query)\n",
        "    sparql.setReturnFormat(JSON)\n",
        "    result = sparql.query().convert()\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 532,
      "metadata": {
        "id": "0mhCVxOasGZp"
      },
      "outputs": [],
      "source": [
        "#Function to show JSON results in a readable manner\n",
        "def json_result_to_dataframe(json_result):\n",
        "    cols = json_result[\"head\"][\"vars\"]\n",
        "    data = [\n",
        "        {key: value[\"value\"] for key, value in row.items()}\n",
        "        for row in json_result[\"results\"][\"bindings\"]\n",
        "    ]\n",
        "    df = pd.DataFrame(data, columns=cols)\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating a reduced ontology from the original ontology\n",
        "def create_reduced_ontology():\n",
        "  sparql_query_classes = \"select distinct ?class FROM <http://data.europa.eu/949/graph/rinf> where { ?subj a ?class . }\"\n",
        "  sparql_query_properties = \"select distinct ?pred FROM <http://data.europa.eu/949/graph/rinf> where { ?subj ?pred ?obj . }\"\n",
        "\n",
        "  s1 = execute_sparql_query(endpoint_url, sparql_query_classes )    #returns JSON format\n",
        "  s2 = execute_sparql_query(endpoint_url, sparql_query_properties)  #returns JSON Formet\n",
        "\n",
        "  relevant_classes = []\n",
        "  for item in s1['results']['bindings']:\n",
        "    x = item.get(\"class\", {}).get(\"value\", \"\")\n",
        "    relevant_classes.append(x)\n",
        "\n",
        "  relevant_properties = []\n",
        "  for item in s2[\"results\"][\"bindings\"]:\n",
        "    x = item.get(\"pred\", {}).get(\"value\", \"\")\n",
        "    relevant_properties.append(x)\n",
        "  \n",
        "  reduced_graph = Graph()\n",
        "  r_classes = Graph()\n",
        "  r_prop = Graph() \n",
        "  \n",
        "  for classes in relevant_classes:\n",
        "    r_classes += org_ontology.triples((URIRef(classes),None,None))\n",
        "    reduced_graph += org_ontology.triples((URIRef(classes),None,None))  #.triples() function returns triples that matches the given pattern.\n",
        "  \n",
        "  for prop in relevant_properties:\n",
        "    for s,p,o in org_ontology:\n",
        "        if p == URIRef(prop) and not isinstance(s,BNode):\n",
        "            reduced_graph.add((s,p,o))\n",
        "            r_prop.add((s,p,o))\n",
        "  \n",
        "  r_classes.serialize(destination=\"F:/main_proj/reduced_classes.ttl\", format=\"turtle\")\n",
        "  r_prop.serialize(destination=\"F:/main_proj/reduced_properties.ttl\", format=\"turtle\")\n",
        "  reduced_graph.serialize(destination=\"F:/main_proj/reduced_graph.ttl\", format=\"turtle\")\n",
        " \n",
        "  return reduced_graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# build vocabulary of main classes, class instances and properties from the reduced graph.\n",
        "def extract_ontology_structure(reduced_graph):\n",
        "    \n",
        "    main_classes = set()  \n",
        "    properties = set()\n",
        "    instances_of_class = set()\n",
        "\n",
        "    for s, p, o in reduced_graph:\n",
        "            if p == RDF.type and o != rdflib.RDFS.Class: #check if the object is class of main ontology and not a general RDFS:class\n",
        "                main_classes.add(str(o))\n",
        "                instances_of_class.add(str(s))\n",
        "            else:\n",
        "                properties.add(str(p))\n",
        "\n",
        "    ontology_structure = {}\n",
        "    ontology_structure[\"classes\"] = list(main_classes)\n",
        "    ontology_structure[\"properties\"] = list(properties)\n",
        "    ontology_structure[\"instances\"] = list(instances_of_class)\n",
        "    \n",
        "    return ontology_structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "reduced_graph = create_reduced_ontology()\n",
        "ontology_information = extract_ontology_structure(reduced_graph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def MyVocab_prompt(question, ontology_information): #working perfenctly with temperture 0.4\n",
        "    \n",
        "    prompt = (\n",
        "      f\"Consider the below ontology Information:\\n\"\n",
        "      f\"{ontology_information}\\n\"\n",
        "      f\"Based on the given ontology above, generate a SPARQL query for the question delimited by triple backticks taking into consideration the below restrictions:\"\n",
        "      f\"-Only use classes, properties and instances URIs defined in the ontology_information provided.\"\n",
        "      f\"-use full URI.\"\n",
        "      f\"-Use simple letters such as x for variables.\"\n",
        "      f\"-Always include the \\\"PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\\\" in your answer.\"\n",
        "      f\"Question: ```{question}```\")\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "d0aGT0DMydXw"
      },
      "outputs": [],
      "source": [
        "#prompt with reduced graph\n",
        "def prompt_ntGraph(question,reduced_graph):\n",
        "  rg = reduced_graph.serialize(format='turtle')\n",
        "  prompt = (\n",
        "      f\"Given the following RDF graph serialized in Turtle format: \\n{rg}\\n\"\n",
        "      f\"Generate a correct SPARQL query for the question delimited by Parentheses following the below restrictions:\"\n",
        "      f\"-Only use classes, properties and instances defined in the RDF graph.\\n\"\n",
        "      f\"-Do not use any modifiers unless it is instrcuted\\n\"\n",
        "      f\"-Always Use namespaces prefix bindings.\"\n",
        "      f\"-Always include prefixes and namespaces used in the RDF in your response.\\n\"\n",
        "      f\"-Always include the \\\"PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\\\" in your answer.\"\n",
        "      f\"-Always include the \\\"PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#> \\\" in your answer.\"\n",
        "      f\"Question: ({question})\"\n",
        "  )\n",
        "  return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def structured_prompt(question, reduced_graph):\n",
        "    rg = reduced_graph.serialize(format = 'turtle')\n",
        "    prompt = f\"\"\"\n",
        "    Consider the RDF graph:\\n {rg}\n",
        "    Generate a SPARQL query for the given question: {question}.\n",
        "    Instructions to Follow:\n",
        "    -Always Use namespaces prefix bindings.\n",
        "    -Always include prefixes and namespaces used in the RDF in your response.\n",
        "    -Always include the \\\"PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\\\" in your answer.\n",
        "    -Always include the \\\"PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#> \\\" in your answer.\n",
        "    \"\"\"\n",
        "    return prompt\n",
        "\n",
        "#- Do not use modifiers unless it is instrcuted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oxf0OdqwGkUH"
      },
      "outputs": [],
      "source": [
        "# API to chatgpt 3.5 Turbo\n",
        "def openai_api(prompt):\n",
        "  completion =[]\n",
        "  openai.api_key = \"\"\n",
        "\n",
        "  completion = openai.chat.completions.create(\n",
        "      model=\"gpt-3.5-turbo\",\n",
        "      temperature = 0.4,\n",
        "      messages=[\n",
        "          {\"role\":\"user\", \"content\": prompt}\n",
        "      ]\n",
        "  )\n",
        "  return completion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "id": "kLCnYOWs3X2V"
      },
      "outputs": [],
      "source": [
        "# API To Gemini\n",
        "def gemini_api(prompt):\n",
        "\n",
        "  model = genai.GenerativeModel('gemini-pro')\n",
        "  response = model.generate_content(prompt,generation_config=genai.types.GenerationConfig(\n",
        "      candidate_count=1,\n",
        "      max_output_tokens=1000,\n",
        "      temperature=0.4)\n",
        "  )\n",
        "  return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {
        "id": "teorsReBldQg"
      },
      "outputs": [],
      "source": [
        "nl_input = \"what is the maximum temperture range for the track with label TRL1?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {},
      "outputs": [],
      "source": [
        "questions_list = [\"Please give me a list of all operational points.\",\n",
        "\"Please give me a list of distinct train detection systems.\",\n",
        "\"Please give me a list of all national railway lines.\",\n",
        "\"Please give me a list of all national railway lines, Limit to 100 results.\",\n",
        "\"Please give me a list of all national railway lines, return the name of the resource only, Limit to 100 results.\",\n",
        "\"Please give me all operational points names and then filter results to find all operational points in Bournemouth.\",\n",
        "\"give me a list of all tunnel names.\",\n",
        "\"give me the length of all section of lines, return section of line label and corresponding length.\",\n",
        "\"give me the Unique OP ID for the operational point Siding_BBD9.\",\n",
        "\"Please give me a list of distinct train detection systems.\",\n",
        "\"what is the maximum temperture range for the track with label TRL1.\",\n",
        "\"give me a list of all tracks that have maximum temperture range of 40.\",\n",
        "\"in which country is the operational point Rakenduspunkt Kiisa is located?.\",\n",
        "\"which country has the largest number of operational points?.\",\n",
        "\"which country has the largest number of tunnels?.\",\n",
        "\"Get me all information about operational point Siding_BBD9.\",\n",
        "\"Give me the country of operational point labeled as Siding_BBD9.\",\n",
        "\"list all siding values for the Siding_BBD9 operational point.\",\n",
        "\"Please give me all section of lines and then filter results to find bournemouth.\",\n",
        "\"which country has the longest length of section of lines?.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Generate in context Prompts to be fed to LLM\n",
        "\n",
        "prompt1 = MyVocab_prompt(nl_input,ontology_information)\n",
        "prompt2 = prompt_ntGraph(nl_input,reduced_graph)\n",
        "prompt3 = structured_prompt(nl_input,reduced_graph)\n",
        "\n",
        "prompt_list = [prompt1,prompt2,prompt3]\n",
        "\n",
        "# run prompt_list against using openAI API\n",
        "print(\"# \" + nl_input)\n",
        "print(\"# gpt-3.5-turbo\")\n",
        "for item in prompt_list:\n",
        " answer = openai_api(item)\n",
        " print(answer.choices[0].message.content)\n",
        " print(\"----------------------------------------------\\n\")\n",
        "\n",
        "# run prompt_list against using Gemini API\n",
        "print(\"# \" + nl_input)\n",
        "print(\"# Gemini\" )\n",
        "response_list = []\n",
        "for item in prompt_list:\n",
        "  response = gemini_api(item)\n",
        "  response_list.append(response.text)\n",
        "\n",
        "  print(response.text)\n",
        "  print(\"----------------------------------------------\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
